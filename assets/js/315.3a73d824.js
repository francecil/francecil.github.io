(window.webpackJsonp=window.webpackJsonp||[]).push([[315],{1208:function(t,e,a){"use strict";a.r(e);var v=a(30),s=Object(v.a)({},(function(){var t=this,e=t._self._c;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h1",{attrs:{id:"jsmpeg是什么"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#jsmpeg是什么"}},[t._v("#")]),t._v(" jsmpeg是什么？")]),t._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[t._v("https://github.com/phoboslab/jsmpeg\n")])])]),e("p",[t._v("一个"),e("a",{attrs:{href:"http://baike.baidu.com/link?url=IdDNfUYYiss4iUee-J5RKHujDyCinU3pO07wdRGuMfEHw9Ih3OaoOHbCRwTuMT_ktsTwTgvniHVHVrmBZu3G8K",target:"_blank",rel:"noopener noreferrer"}},[t._v("mpeg-1"),e("OutboundLink")],1),t._v(" video的js解码库")]),t._v(" "),e("h1",{attrs:{id:"jsmpeg可以用来干什么"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#jsmpeg可以用来干什么"}},[t._v("#")]),t._v(" jsmpeg可以用来干什么？")]),t._v(" "),e("p",[t._v("利用ffmpeg采集视频源并推送到node.js服务器\nnodejs利用ws模块*[基于tcp]*将数据包转发到网页，利用该js进行解码，提供canvas渲染\n最后的效果就是浏览器能够实时看到视频源的数据")]),t._v(" "),e("blockquote",[e("p",[t._v("使用方法请参考github\n本电脑使用记录")])]),t._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[t._v('1. cd到对应目录D:\\nodejs\\projects\\live_audio \n2. node stream-server.js ququ 9091 9092\n3. ffmpeg -f dshow -i video="Integrated Webcam"  -f mpeg1video -b 500k -r 20 -vf scale=640:360  http://localhost:9091/ququ/640/360\n')])])]),e("h1",{attrs:{id:"应用场景"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#应用场景"}},[t._v("#")]),t._v(" 应用场景")]),t._v(" "),e("p",[t._v("基本直播场景都可以用到**[注意是基于tcp的]**\n但是注意！！这个是只有视频 没有音频\nPS:关于音频以及利用流媒体协议或封装格式做同步的下篇文章会写到")]),t._v(" "),e("h1",{attrs:{id:"mpeg-1-video-简介"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#mpeg-1-video-简介"}},[t._v("#")]),t._v(" mpeg-1 video 简介")]),t._v(" "),e("blockquote",[e("p",[t._v("随机访问\n灵活的帧率"),e("code",[t._v("（最大25帧/s）")]),t._v("\n可变的图像尺寸"),e("code",[t._v("(最大720*576)")]),t._v("\n定义了"),e("code",[t._v("I-帧")]),t._v("、"),e("code",[t._v("P-帧（参考之前的I或P）")]),t._v("和"),e("code",[t._v("B-帧（参考前后的I或P 实时流不用这个）")]),t._v("\n运动补偿可跨越多个帧\n半像素精度的运动向量 、量化矩阵、GOF结构 、slice结构\n版权：free")])]),t._v(" "),e("p",[e("strong",[t._v("满足多达16路以上25帧/秒的压缩速度，在500kbit/s的压缩码流和352像素×288行的清晰度下，每帧大小仅为2k")])]),t._v(" "),e("h1",{attrs:{id:"mpeg-1-video-编码简介"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#mpeg-1-video-编码简介"}},[t._v("#")]),t._v(" mpeg-1 video 编码简介")]),t._v(" "),e("p",[t._v("这边只是说一下简单的做法，或者说是视频编码的基本做法 忽略了很多细节..\nh164和mpeg1都是在此基础上进行改进的")]),t._v(" "),e("p",[t._v("参考")]),t._v(" "),e("blockquote",[e("p",[t._v("http://blog.jobbole.com/95862/\nhttp://blog.csdn.net/leixiaohua1020/article/details/28114081")])]),t._v(" "),e("h2",{attrs:{id:"_1-i帧-i-frames"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_1-i帧-i-frames"}},[t._v("#")]),t._v(" （1）I帧(I-frames)")]),t._v(" "),e("p",[t._v("不依赖于其他视频帧\n帧内压缩，jpeg编码技术,采用离散余弦变换DCT的压缩技术，GOP(帧组)的第一帧且一组只有一个I帧，不考虑运动矢量")]),t._v(" "),e("h3",{attrs:{id:"变换编码-二维dct"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#变换编码-二维dct"}},[t._v("#")]),t._v(" 变换编码-二维DCT")]),t._v(" "),e("ol",[e("li",[t._v("假设一帧图像的大小为1280 * 720，首先将其以网格状的形式分成160 * 90个尺寸为8 * 8的彼此没有重叠的图像块")]),t._v(" "),e("li",[t._v("每个8 * 8点的图像块被送入DCT编码器，将8 * 8的图像块从空间域变换为频率域")]),t._v(" "),e("li",[t._v("一个实际8*8图像块[亮度值] 相邻像素亮度值差距不大\n"),e("img",{attrs:{src:"http://img.blog.csdn.net/20140602173641875?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center",alt:"请输入图片描述"}})]),t._v(" "),e("li",[t._v("图像块经过DCT变换后的系数\n"),e("img",{attrs:{src:"http://img.blog.csdn.net/20140602173658734?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center",alt:"图像块经过DCT变换后的系数"}})])]),t._v(" "),e("p",[t._v("从图中可以看出，左上角(低频系数)集中大量能量，右下角(高频系数)能量小")]),t._v(" "),e("ol",{attrs:{start:"5"}},[e("li",[t._v("量化-有损压缩。人眼对低频敏感对高频不敏感，故对低频区的系数进行细量化，高频区的系数进行粗量化。\n"),e("strong",[t._v("量化公式")]),t._v("："),e("img",{attrs:{src:"http://img.blog.csdn.net/20140602173713140?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center",alt:"请输入图片描述"}})])]),t._v(" "),e("p",[t._v("其中"),e("code",[t._v("FQ（u,v）")]),t._v("表示经过量化后的DCT系数；\n"),e("code",[t._v("F（u,v）")]),t._v("表示量化前的DCT系数；\n"),e("code",[t._v("Q（u,v）")]),t._v("表示量化加权矩阵；\n"),e("code",[t._v("q")]),t._v("表示量化步长；\n"),e("code",[t._v("round")]),t._v("表示归整，即将输出的值取为与之最接近的整数值。\n合理选择量化系数，对变换后的图像块进行量化后的结果如图所示。\n"),e("img",{attrs:{src:"http://img.blog.csdn.net/20140602173723046?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center",alt:"请输入图片描述"}})]),t._v(" "),e("p",[t._v("DCT系数量化后大部分为变为0，将少部分非0值进行压缩编码即可。")]),t._v(" "),e("h3",{attrs:{id:"熵编码"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#熵编码"}},[t._v("#")]),t._v(" 熵编码")]),t._v(" "),e("p",[t._v("多用可变字长编码(VLC) 实现\n基本原理是对信源中"),e("strong",[t._v("出现概率大的符号赋予短码")]),t._v("，对于"),e("strong",[t._v("出现概率小的符号赋予长码")]),t._v("，从而在统计上获得较短的平均码长。\n游程编码"),e("code",[t._v("[常用，压缩效率不高，但编解码快]")]),t._v("\n参考："),e("a",{attrs:{href:"http://blog.jobbole.com/79758/",target:"_blank",rel:"noopener noreferrer"}},[t._v("计算机算法：数据压缩之游程编码"),e("OutboundLink")],1),t._v("\n实现：")]),t._v(" "),e("ol",[e("li",[t._v("在上图量化DCT时对结果进行"),e("code",[t._v("Z-型扫描")]),t._v("化为一维序列(按图箭头方向)")]),t._v(" "),e("li",[t._v("将该一维序列进行游程编码")]),t._v(" "),e("li",[t._v("对编码后的数据再次进行VLC ( 比如 "),e("code",[t._v("Huffman")]),t._v("编码")])]),t._v(" "),e("h2",{attrs:{id:"_2-p帧"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-p帧"}},[t._v("#")]),t._v(" （2）P帧")]),t._v(" "),e("p",[t._v("播放解码时需要依赖于前面已解码的参考帧\n需要帧存储器")]),t._v(" "),e("blockquote",[e("p",[t._v("PS:解码时如果都依赖I帧就比较简单，保存一份I帧数据到帧存储器即可，否则由于不知道参考的哪一帧 需要保存GOP里的所有I P到帧存储器")])]),t._v(" "),e("p",[t._v("编码时直接拿前面参考帧的未编码数据")]),t._v(" "),e("h3",{attrs:{id:"运动预测"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#运动预测"}},[t._v("#")]),t._v(" 运动预测")]),t._v(" "),e("p",[t._v("将参考帧(P1,可以是I帧也可以是P帧)，预测帧(P2,待编码的P帧) 分块(例如将图像分割成n个16*16图像块)\n定义两个颜色的误差为：")]),t._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[t._v("PixelDiff(c1, c2) = (c1- c2) ^ 2\n")])])]),e("p",[t._v("两个图像块之间的误差即16*16个PixelDiff的sum")]),t._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[t._v("int block_diff(const unsigned char b1[16][16], const unsigned char b2[16][16]) { \n    int sum = 0; \n    for (int i = 0; i < 16; i++) { \n         for (int j = 0; j < 16; j++) { \n              int c1 = b1[i][j]; \n              int c2 = b2[i][j]; \n              sum += (c1 – c2) * (c1 – c2); \n         } \n    } \n    return sum; \n}\n")])])]),e("p",[t._v("P2中每一个block找出上一帧中相似度最高的block坐标，并记录下来\n做法可以直接2个for循环(暴力)\n当然实际中不可能这么暴力搜索，而是围绕P2中该block对应坐标在P1中位置作为中心，慢慢四周扩散，搜索***一定步长,在一定误差范围内的宏块坐标***。\n所以结果是，P2进行运动预测编码的结果就是一大堆(x,y)的坐标，代表P2上每个block在上一帧P1里面最相似的 block的位置")]),t._v(" "),e("h3",{attrs:{id:"p帧编码"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#p帧编码"}},[t._v("#")]),t._v(" P帧编码")]),t._v(" "),e("p",[t._v("刚才的运动预测矢量（一堆block的坐标），我们先用P1按照这些数据拼凑出一张类似P2的新图片叫做P2’，然后同P2上"),e("strong",[t._v("每个像素")]),t._v("做减法，得到一张保存differ的图片：")]),t._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[t._v("D = (P2 – P2′) / 2 \n")])])]),e("p",[t._v("用一个 "),e("code",[t._v("8位的整数(只够表示256个数字)")]),t._v(" 可以表示 [-255, 255] 之间的误差范围，步长精度是2。")]),t._v(" "),e("blockquote",[e("p",[t._v("即-2 -3映射到-1 (1000001) 解码时*2即可")])]),t._v(" "),e("p",[t._v("由于是 "),e("strong",[t._v("图片细节的修改")]),t._v("，比起I帧这种一整张图的图片 "),e("strong",[t._v("熵要低很多")]),t._v("，占的空间也比较小\n然后将D用类似于jpeg的算法进行编码 "),e("strong",[e("code",[t._v("[DCT+熵编码]")])]),t._v("\n故P帧的完整编码为：")]),t._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[t._v("Encode(P2)=记录P1 block位置(x,y)的矩阵+类jpeg有损图像编码(D)\n")])])]),e("h2",{attrs:{id:"_3-gop"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_3-gop"}},[t._v("#")]),t._v(" （3）GOP")]),t._v(" "),e("p",[t._v("实时传输收到B帧无法播放，这里就不介绍B帧了，一般 I P 就足够了\n一个GOP是这样的 I P1 P2 P3 P4...\n一般 P1 - Pn 都参考I 就好了， 虽然参考P可以得到更高的压缩空间")]),t._v(" "),e("h2",{attrs:{id:"_4-视频容器"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_4-视频容器"}},[t._v("#")]),t._v(" （4）视频容器")]),t._v(" "),e("p",[t._v("mpg 记录视频信息，比如分辨率，帧率，时间索引")]),t._v(" "),e("h2",{attrs:{id:"_5-优化"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-优化"}},[t._v("#")]),t._v(" （5）优化")]),t._v(" "),e("p",[t._v("编码效率优化：追求同质量（同信噪比）下更低的码率\n编码性能优化：追求同样质量和码率的情况下，更快的编码速度。")]),t._v(" "),e("h1",{attrs:{id:"混合编码模型"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#混合编码模型"}},[t._v("#")]),t._v(" 混合编码模型")]),t._v(" "),e("p",[e("img",{attrs:{src:"http://img.blog.csdn.net/20140602173439593?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast",alt:"请输入图片描述"}})]),t._v(" "),e("p",[t._v("应用于MPEG1，MPEG2，H.264等标准中")]),t._v(" "),e("h1",{attrs:{id:"mpeg1-标准"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#mpeg1-标准"}},[t._v("#")]),t._v(" MPEG1 标准")]),t._v(" "),e("p",[t._v("与刚刚所说的简单编码所谓的优化。\nMPEG1是保存的是YCbCr的4:2:2\n关于YCbCr可以参考"),e("a",{attrs:{href:"http://blog.sina.com.cn/s/blog_a85e142101010h8n.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("RGB、YUV和YCbCr"),e("OutboundLink")],1)]),t._v(" "),e("p",[t._v("待更新。。")])])}),[],!1,null,null,null);e.default=s.exports}}]);