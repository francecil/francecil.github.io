(window.webpackJsonp=window.webpackJsonp||[]).push([[356],{1118:function(t,e,a){"use strict";a.r(e);var r=a(28),s=Object(r.a)({},(function(){var t=this,e=t._self._c;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("p",[t._v("服务利用率指的是服务用于处理请求所花费的时间百分比。")]),t._v(" "),e("h2",{attrs:{id:"排队论-little-s-law"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#排队论-little-s-law"}},[t._v("#")]),t._v(" 排队论 Little’s Law")]),t._v(" "),e("p",[e("code",[t._v("L = λ * W")])]),t._v(" "),e("ul",[e("li",[t._v("L：系统中的平均请求数（同时包括正在接受服务的请求和等待服务的请求）")]),t._v(" "),e("li",[t._v("λ：单位时间内到达系统的请求数量，即到达率。")]),t._v(" "),e("li",[t._v("W：请求在系统中的平均逗留时间，即用户感知到的延迟包括排队时间和服务时间（实际执行耗时）。")])]),t._v(" "),e("p",[t._v("假设服务同时只能处理一个请求，则服务利用率 P = 请求间隔/服务耗时")]),t._v(" "),e("p",[t._v("当 P < 1，请求队列处于稳定状态。反之如果 P > 1，将会出现请求队列积压，需要进行等待")]),t._v(" "),e("h2",{attrs:{id:"一些结论"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#一些结论"}},[t._v("#")]),t._v(" 一些结论")]),t._v(" "),e("ul",[e("li",[t._v("系统利用率（μ）与延时率（W）成反比。提升处理能力后，也能线性的减少访问延迟")])]),t._v(" "),e("h2",{attrs:{id:"实例分析-browserless"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#实例分析-browserless"}},[t._v("#")]),t._v(" 实例分析（browserless）")]),t._v(" "),e("h2",{attrs:{id:"拓展阅读"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#拓展阅读"}},[t._v("#")]),t._v(" 拓展阅读")]),t._v(" "),e("ul",[e("li",[e("a",{attrs:{href:"https://www.infoq.cn/article/2016/02/utilisation-wait-latency",target:"_blank",rel:"noopener noreferrer"}},[t._v("为什么超过 80% 的资源利用率会成为任何系统的噩梦"),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://blog.betacat.io/post/2023/05/explain-latency-and-utilization-using-queueing-theory/",target:"_blank",rel:"noopener noreferrer"}},[t._v("用排队论解释延时与利用率的关系"),e("OutboundLink")],1)])])])}),[],!1,null,null,null);e.default=s.exports}}]);